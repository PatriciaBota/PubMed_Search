Title,Journal,PublicationDate,Abstract,DOI
Deep-Learning for Epicardial Adipose Tissue Assessment With Computed Tomography: Implications for Cardiovascular Risk Prediction.,JACC. Cardiovascular imaging,2023,Epicardial adipose tissue (EAT) volume is a marker of visceral obesity that can be measured in coronary computed tomography angiograms (CCTA). The clinical value of integrating this measurement in routine CCTA interpretation has not been documented.,10.1016/j.jcmg.2022.11.018
Severe aortic stenosis detection by deep learning applied to echocardiography.,European heart journal,2023,"Early diagnosis of aortic stenosis (AS) is critical to prevent morbidity and mortality but requires skilled examination with Doppler imaging. This study reports the development and validation of a novel deep learning model that relies on two-dimensional (2D) parasternal long axis videos from transthoracic echocardiography without Doppler imaging to identify severe AS, suitable for point-of-care ultrasonography.",10.1093/eurheartj/ehad456
Revival and Revision of Right Ventricular Assessment by Machine Learning.,JACC. Cardiovascular imaging,2022,,10.1016/j.jcmg.2022.01.019
Deep Learning and Biased Prediction: More Questions Than Answers?,Circulation. Heart failure,2024,,10.1161/CIRCHEARTFAILURE.123.011368
Deep Learning on Bone Scintigraphy to Detect Abnormal Cardiac Uptake at Risk of Cardiac Amyloidosis.,JACC. Cardiovascular imaging,2023,"Cardiac uptake on technetium-99m whole-body scintigraphy (WBS) is almost pathognomonic of transthyretin cardiac amyloidosis. The rare false positives are often related to light-chain cardiac amyloidosis. However, this scintigraphic feature remains largely unknown, leading to misdiagnosis despite characteristic images. A retrospective review of all WBSs in a hospital database to detect those with cardiac uptake may allow the identification of undiagnosed patients.",10.1016/j.jcmg.2023.01.014
A multimodal deep learning model for cardiac resynchronisation therapy response prediction.,Medical image analysis,2022,"We present a novel multimodal deep learning framework for cardiac resynchronisation therapy (CRT) response prediction from 2D echocardiography and cardiac magnetic resonance (CMR) data. The proposed method first uses the 'nnU-Net' segmentation model to extract segmentations of the heart over the full cardiac cycle from the two modalities. Next, a multimodal deep learning classifier is used for CRT response prediction, which combines the latent spaces of the segmentation models of the two modalities. At test time, this framework can be used with 2D echocardiography data only, whilst taking advantage of the implicit relationship between CMR and echocardiography features learnt from the model. We evaluate our pipeline on a cohort of 50 CRT patients for whom paired echocardiography/CMR data were available, and results show that the proposed multimodal classifier results in a statistically significant improvement in accuracy compared to the baseline approach that uses only 2D echocardiography data. The combination of multimodal data enables CRT response to be predicted with 77.38% accuracy (83.33% sensitivity and 71.43% specificity), which is comparable with the current state-of-the-art in machine learning-based CRT response prediction. Our work represents the first multimodal deep learning approach for CRT response prediction.",10.1016/j.media.2022.102465
Cardiac MRI segmentation with sparse annotations: Ensembling deep learning uncertainty and shape priors.,Medical image analysis,2022,"The performance of deep learning for cardiac magnetic resonance imaging (MRI) segmentation is oftentimes degraded when using small datasets and sparse annotations for training or adapting a pre-trained model to previously unseen datasets. Here, we developed and evaluated an approach to addressing some of these issues to facilitate broader use of deep learning for short-axis cardiac MRI segmentation. We developed a globally optimal label fusion (GOLF) algorithm that enforced spatial smoothness to generate consensus segmentation from segmentation predictions provided by a deep learning ensemble algorithm. The GOLF consensus was entered into an uncertainty-guided coupled continuous kernel cut (ugCCKC) algorithm that employed normalized cut, image-grid continuous regularization, and ""nesting"" and circular shape priors of the left ventricular myocardium (LVM) and cavity (LVC). In addition, the uncertainty measurements derived from the segmentation predictions were used to constrain the similarity of GOLF and final segmentation. We optimized ugCCKC through upper bound relaxation, for which we developed an efficient coupled continuous max-flow algorithm implemented in an iterative manner. We showed that GOLF yielded average symmetric surface distance (ASSD) 0.2-0.8 mm lower than an averaging method with higher or similar Dice similarity coefficient (DSC). We also demonstrated that ugCCKC incorporating the shape priors improved DSC by 0.01-0.05 and reduced ASSD by 0.1-0.9 mm. In addition, we integrated GOLF and ugCCKC into a deep learning ensemble algorithm by refining the segmentation of an unannotated dataset and using the refined segmentation to update the trained models. With the proposed framework, we demonstrated the capability of using relatively small datasets (5-10 subjects) with sparse (5-25% slices labeled) annotations to train a deep learning algorithm, while achieving DSC of 0.871-0.893 for LVM and 0.933-0.959 for LVC on the LVQuan dataset, and these were 0.844-0.871 for LVM and 0.923-0.931 for LVC on the ACDC dataset. Furthermore, we showed that the proposed approach can be adapted to substantially alleviate the domain shift issue. Moreover, we calculated a number of commonly used LV function measurements using the derived segmentation and observed strong correlations (Pearson r=0.77-1.00, p<0.001) between algorithm and manual LV function analyses. These results suggest that the developed approaches can be used to facilitate broader application of deep learning in research and clinical cardiac MR imaging workflow.",10.1016/j.media.2022.102532
"Disentangle, Align and Fuse for Multimodal and Semi-Supervised Image Segmentation.",IEEE transactions on medical imaging,2021,"Magnetic resonance (MR) protocols rely on several sequences to assess pathology and organ status properly. Despite advances in image analysis, we tend to treat each sequence, here termed modality, in isolation. Taking advantage of the common information shared between modalities (an organ's anatomy) is beneficial for multi-modality processing and learning. However, we must overcome inherent anatomical misregistrations and disparities in signal intensity across the modalities to obtain this benefit. We present a method that offers improved segmentation accuracy of the modality of interest (over a single input model), by learning to leverage information present in other modalities, even if few (semi-supervised) or no (unsupervised) annotations are available for this specific modality. Core to our method is learning a disentangled decomposition into anatomical and imaging factors. Shared anatomical factors from the different inputs are jointly processed and fused to extract more accurate segmentation masks. Image misregistrations are corrected with a Spatial Transformer Network, which non-linearly aligns the anatomical factors. The imaging factor captures signal intensity characteristics across different modality data and is used for image reconstruction, enabling semi-supervised learning. Temporal and slice pairing between inputs are learned dynamically. We demonstrate applications in Late Gadolinium Enhanced (LGE) and Blood Oxygenation Level Dependent (BOLD) cardiac segmentation, as well as in T2 abdominal segmentation. Code is available at https://github.com/vios-s/multimodal_segmentation.",10.1109/TMI.2020.3036584
Explainable AI for ECG-based prediction of cardiac resynchronization therapy outcomes: learning from machine learning?,European heart journal,2023,,10.1093/eurheartj/ehac733
Using deep learning for an automatic detection and classification of the vascular bifurcations along the Circle of Willis.,Medical image analysis,2023,"Most of the intracranial aneurysms (ICA) occur on a specific portion of the cerebral vascular tree named the Circle of Willis (CoW). More particularly, they mainly arise onto fifteen of the major arterial bifurcations constituting this circular structure. Hence, for an efficient and timely diagnosis it is critical to develop some methods being able to accurately recognize each Bifurcation of Interest (BoI). Indeed, an automatic extraction of the bifurcations presenting the higher risk of developing an ICA would offer the neuroradiologists a quick glance at the most alarming areas. Due to the recent efforts on Artificial Intelligence, Deep Learning turned out to be the best performing technology for many pattern recognition tasks. Moreover, various methods have been particularly designed for medical image analysis purposes. This study intends to assist the neuroradiologists to promptly locate any bifurcation presenting a high risk of ICA occurrence. It can be seen as a Computer Aided Diagnosis scheme, where the Artificial Intelligence facilitates the access to the regions of interest within the MRI. In this work, we propose a method for a fully automatic detection and recognition of the bifurcations of interest forming the Circle of Willis. Several neural networks architectures have been tested, and we thoroughly evaluate the bifurcation recognition rate.",10.1016/j.media.2023.102919
DeepMesh: Mesh-Based Cardiac Motion Tracking Using Deep Learning.,IEEE transactions on medical imaging,2024,"3D motion estimation from cine cardiac magnetic resonance (CMR) images is important for the assessment of cardiac function and the diagnosis of cardiovascular diseases. Current state-of-the art methods focus on estimating dense pixel-/voxel-wise motion fields in image space, which ignores the fact that motion estimation is only relevant and useful within the anatomical objects of interest, e.g., the heart. In this work, we model the heart as a 3D mesh consisting of epi- and endocardial surfaces. We propose a novel learning framework, DeepMesh, which propagates a template heart mesh to a subject space and estimates the 3D motion of the heart mesh from CMR images for individual subjects. In DeepMesh, the heart mesh of the end-diastolic frame of an individual subject is first reconstructed from the template mesh. Mesh-based 3D motion fields with respect to the end-diastolic frame are then estimated from 2D short- and long-axis CMR images. By developing a differentiable mesh-to-image rasterizer, DeepMesh is able to leverage 2D shape information from multiple anatomical views for 3D mesh reconstruction and mesh motion estimation. The proposed method estimates vertex-wise displacement and thus maintains vertex correspondences between time frames, which is important for the quantitative assessment of cardiac function across different subjects and populations. We evaluate DeepMesh on CMR images acquired from the UK Biobank. We focus on 3D motion estimation of the left ventricle in this work. Experimental results show that the proposed method quantitatively and qualitatively outperforms other image-based and mesh-based cardiac motion tracking methods.",10.1109/TMI.2023.3340118
Deep Learning-Based ECG-Free Cardiac Navigation for Multi-Dimensional and Motion-Resolved Continuous Magnetic Resonance Imaging.,IEEE transactions on medical imaging,2021,"For the clinical assessment of cardiac vitality, time-continuous tomographic imaging of the heart is used. To further detect e.g., pathological tissue, multiple imaging contrasts enable a thorough diagnosis using magnetic resonance imaging (MRI). For this purpose, time-continous and multi-contrast imaging protocols were proposed. The acquired signals are binned using navigation approaches for a motion-resolved reconstruction. Mostly, external sensors such as electrocardiograms (ECG) are used for navigation, leading to additional workflow efforts. Recent sensor-free approaches are based on pipelines requiring prior knowledge, e.g., typical heart rates. We present a sensor-free, deep learning-based navigation that diminishes the need for manual feature engineering or the necessity of prior knowledge compared to previous works. A classifier is trained to estimate the R-wave timepoints in the scan directly from the imaging data. Our approach is evaluated on 3-D protocols for continuous cardiac MRI, acquired in-vivo and free-breathing with single or multiple imaging contrasts. We achieve an accuracy of > 98% on previously unseen subjects, and a well comparable image quality with the state-of-the-art ECG-based reconstruction. Our method enables an ECG-free workflow for continuous cardiac scans with simultaneous anatomic and functional imaging with multiple contrasts. It can be potentially integrated without adapting the sampling scheme to other continuous sequences by using the imaging data for navigation and reconstruction.",10.1109/TMI.2021.3073091
Deep learning to detect left ventricular structural abnormalities in chest X-rays.,European heart journal,2024,"Early identification of cardiac structural abnormalities indicative of heart failure is crucial to improving patient outcomes. Chest X-rays (CXRs) are routinely conducted on a broad population of patients, presenting an opportunity to build scalable screening tools for structural abnormalities indicative of Stage B or worse heart failure with deep learning methods. In this study, a model was developed to identify severe left ventricular hypertrophy (SLVH) and dilated left ventricle (DLV) using CXRs.",10.1093/eurheartj/ehad782
Deep Learning-Based Image Registration in Dynamic Myocardial Perfusion CT Imaging.,IEEE transactions on medical imaging,2023,"Registration of dynamic CT image sequences is a crucial preprocessing step for clinical evaluation of multiple physiological determinants in the heart such as global and regional myocardial perfusion. In this work, we present a deformable deep learning-based image registration method for quantitative myocardial perfusion CT examinations, which in contrast to previous approaches, takes into account some unique challenges such as low image quality with less accurate anatomical landmarks, dynamic changes of contrast agent concentration in the heart chambers and tissue, and misalignment caused by cardiac stress, respiration, and patient motion. The introduced method uses a recursive cascade network with a ventricle segmentation module, and a novel loss function that accounts for local contrast changes over time. It was trained and validated on a dataset of n = 118 patients with known or suspected coronary artery disease and/or aortic valve insufficiency. Our results demonstrate that the proposed method is capable of registering dynamic cardiac perfusion sequences by reducing local tissue displacements of the left ventricle (LV), whereas contrast changes do not affect the registration and image quality, in particular the absolute CT (HU) values of the entire CT sequence. In addition, the deep learning-based approach presented reveals a short processing time of a few seconds compared to conventional image registration methods, demonstrating its application potential for quantitative CT myocardial perfusion measurements in daily clinical routine.",10.1109/TMI.2022.3214380
A New Hope for Deep Learning-Based Echocardiogram Interpretation: The DROIDs You Were Looking For.,Journal of the American College of Cardiology,2023,,10.1016/j.jacc.2023.09.799
Real-time echocardiography image analysis and quantification of cardiac indices.,Medical image analysis,2022,"Deep learning has a huge potential to transform echocardiography in clinical practice and point of care ultrasound testing by providing real-time analysis of cardiac structure and function. Automated echocardiography analysis is benefited through use of machine learning for tasks such as image quality assessment, view classification, cardiac region segmentation, and quantification of diagnostic indices. By taking advantage of high-performing deep neural networks, we propose a novel and eicient real-time system for echocardiography analysis and quantification. Our system uses a self-supervised modality-specific representation trained using a publicly available large-scale dataset. The trained representation is used to enhance the learning of target echo tasks with relatively small datasets. We also present a novel Trilateral Attention Network (TaNet) for real-time cardiac region segmentation. The proposed network uses a module for region localization and three lightweight pathways for encoding rich low-level, textural, and high-level features. Feature embeddings from these individual pathways are then aggregated for cardiac region segmentation. This network is fine-tuned using a joint loss function and training strategy. We extensively evaluate the proposed system and its components, which are echo view retrieval, cardiac segmentation, and quantification, using four echocardiography datasets. Our experimental results show a consistent improvement in the performance of echocardiography analysis tasks with enhanced computational eiciency that charts a path toward its adoption in clinical practice. Specifically, our results show superior real-time performance in retrieving good quality echo from individual cardiac view, segmenting cardiac chambers with complex overlaps, and extracting cardiac indices that highly agree with the experts' values. The source code of our implementation can be found in the project's GitHub page.",10.1016/j.media.2022.102438
Anatomically-aware uncertainty for semi-supervised image segmentation.,Medical image analysis,2024,"Semi-supervised learning relaxes the need of large pixel-wise labeled datasets for image segmentation by leveraging unlabeled data. A prominent way to exploit unlabeled data is to regularize model predictions. Since the predictions of unlabeled data can be unreliable, uncertainty-aware schemes are typically employed to gradually learn from meaningful and reliable predictions. Uncertainty estimation methods, however, rely on multiple inferences from the model predictions that must be computed for each training step, which is computationally expensive. Moreover, these uncertainty maps capture pixel-wise disparities and do not consider global information. This work proposes a novel method to estimate segmentation uncertainty by leveraging global information from the segmentation masks. More precisely, an anatomically-aware representation is first learnt to model the available segmentation masks. The learnt representation thereupon maps the prediction of a new segmentation into an anatomically-plausible segmentation. The deviation from the plausible segmentation aids in estimating the underlying pixel-level uncertainty in order to further guide the segmentation network. The proposed method consequently estimates the uncertainty using a single inference from our representation, thereby reducing the total computation. We evaluate our method on two publicly available segmentation datasets of left atria in cardiac MRIs and of multiple organs in abdominal CTs. Our anatomically-aware method improves the segmentation accuracy over the state-of-the-art semi-supervised methods in terms of two commonly used evaluation metrics.",10.1016/j.media.2023.103011
Multitask Learning for Estimating Multitype Cardiac Indices in MRI and CT Based on Adversarial Reverse Mapping.,IEEE transactions on neural networks and learning systems,2021,"The estimation of multitype cardiac indices from cardiac magnetic resonance imaging (MRI) and computed tomography (CT) images attracts great attention because of its clinical potential for comprehensive function assessment. However, the most exiting model can only work in one imaging modality (MRI or CT) without transferable capability. In this article, we propose the multitask learning method with the reverse inferring for estimating multitype cardiac indices in MRI and CT. Different from the existing forward inferring methods, our method builds a reverse mapping network that maps the multitype cardiac indices to cardiac images. The task dependencies are then learned and shared to multitask learning networks using an adversarial training approach. Finally, we transfer the parameters learned from MRI to CT. A series of experiments were conducted in which we first optimized the performance of our framework via ten-fold cross-validation of over 2900 cardiac MRI images. Then, the fine-tuned network was run on an independent data set with 2360 cardiac CT images. The results of all the experiments conducted on the proposed adversarial reverse mapping show excellent performance in estimating multitype cardiac indices.",10.1109/TNNLS.2020.2984955
Multi-Task Learning for Motion Analysis and Segmentation in 3D Echocardiography.,IEEE transactions on medical imaging,2024,"Characterizing left ventricular deformation and strain using 3D+time echocardiography provides useful insights into cardiac function and can be used to detect and localize myocardial injury. To achieve this, it is imperative to obtain accurate motion estimates of the left ventricle. In many strain analysis pipelines, this step is often accompanied by a separate segmentation step; however, recent works have shown both tasks to be highly related and can be complementary when optimized jointly. In this work, we present a multi-task learning network that can simultaneously segment the left ventricle and track its motion between multiple time frames. Two task-specific networks are trained using a composite loss function. Cross-stitch units combine the activations of these networks by learning shared representations between the tasks at different levels. We also propose a novel shape-consistency unit that encourages motion propagated segmentations to match directly predicted segmentations. Using a combined synthetic and in-vivo 3D echocardiography dataset, we demonstrate that our proposed model can achieve excellent estimates of left ventricular motion displacement and myocardial segmentation. Additionally, we observe strong correlation of our image-based strain measurements with crystal-based strain measurements as well as good correspondence with SPECT perfusion mappings. Finally, we demonstrate the clinical utility of the segmentation masks in estimating ejection fraction and sphericity indices that correspond well with benchmark measurements.",10.1109/TMI.2024.3355383
Non-Rigid Respiratory Motion Estimation of Whole-Heart Coronary MR Images Using Unsupervised Deep Learning.,IEEE transactions on medical imaging,2021,"Non-rigid motion-corrected reconstruction has been proposed to account for the complex motion of the heart in free-breathing 3D coronary magnetic resonance angiography (CMRA). This reconstruction framework requires efficient and accurate estimation of non-rigid motion fields from undersampled images at different respiratory positions (or bins). However, state-of-the-art registration methods can be time-consuming. This article presents a novel unsupervised deep learning-based strategy for fast estimation of inter-bin 3D non-rigid respiratory motion fields for motion-corrected free-breathing CMRA. The proposed 3D respiratory motion estimation network (RespME-net) is trained as a deep encoder-decoder network, taking pairs of 3D image patches extracted from CMRA volumes as input and outputting the motion field between image patches. Using image warping by the estimated motion field, a loss function that imposes image similarity and motion smoothness is adopted to enable training without ground truth motion field. RespME-net is trained patch-wise to circumvent the challenges of training a 3D network volume-wise which requires large amounts of GPU memory and 3D datasets. We perform 5-fold cross-validation with 45 CMRA datasets and demonstrate that RespME-net can predict 3D non-rigid motion fields with subpixel accuracy (0.44 ± 0.38 mm) within ~10 seconds, being ~20 times faster than a GPU-implemented state-of-the-art non-rigid registration method. Moreover, we perform non-rigid motion-compensated CMRA reconstruction for 9 additional patients. The proposed RespME-net has achieved similar motion-corrected CMRA image quality to the conventional registration method regarding coronary artery length and sharpness.",10.1109/TMI.2020.3029205
Myocardial Function Imaging in Echocardiography Using Deep Learning.,IEEE transactions on medical imaging,2021,"Deformation imaging in echocardiography has been shown to have better diagnostic and prognostic value than conventional anatomical measures such as ejection fraction. However, despite clinical availability and demonstrated efficacy, everyday clinical use remains limited at many hospitals. The reasons are complex, but practical robustness has been questioned, and a large inter-vendor variability has been demonstrated. In this work, we propose a novel deep learning based framework for motion estimation in echocardiography, and use this to fully automate myocardial function imaging. A motion estimator was developed based on a PWC-Net architecture, which achieved an average end point error of (0.06±0.04) mm per frame using simulated data from an open access database, on par or better compared to previously reported state of the art. We further demonstrate unique adaptability to image artifacts such as signal dropouts, made possible using trained models that incorporate relevant image augmentations. Further, a fully automatic pipeline consisting of cardiac view classification, event detection, myocardial segmentation and motion estimation was developed and used to estimate left ventricular longitudinal strain in vivo. The method showed promise by achieving a mean deviation of (-0.7±1.6)% compared to a semi-automatic commercial solution for N=30 patients with relevant disease, within the expected limits of agreement. We thus believe that learning-based motion estimation can facilitate extended use of strain imaging in clinical practice.",10.1109/TMI.2021.3054566
Uncertainty aware training to improve deep learning model calibration for classification of cardiac MR images.,Medical image analysis,2023,"Quantifying uncertainty of predictions has been identified as one way to develop more trustworthy artificial intelligence (AI) models beyond conventional reporting of performance metrics. When considering their role in a clinical decision support setting, AI classification models should ideally avoid confident wrong predictions and maximise the confidence of correct predictions. Models that do this are said to be well calibrated with regard to confidence. However, relatively little attention has been paid to how to improve calibration when training these models, i.e. to make the training strategy uncertainty-aware. In this work we: (i) evaluate three novel uncertainty-aware training strategies with regard to a range of accuracy and calibration performance measures, comparing against two state-of-the-art approaches, (ii) quantify the data (aleatoric) and model (epistemic) uncertainty of all models and (iii) evaluate the impact of using a model calibration measure for model selection in uncertainty-aware training, in contrast to the normal accuracy-based measures. We perform our analysis using two different clinical applications: cardiac resynchronisation therapy (CRT) response prediction and coronary artery disease (CAD) diagnosis from cardiac magnetic resonance (CMR) images. The best-performing model in terms of both classification accuracy and the most common calibration measure, expected calibration error (ECE) was the Confidence Weight method, a novel approach that weights the loss of samples to explicitly penalise confident incorrect predictions. The method reduced the ECE by 17% for CRT response prediction and by 22% for CAD diagnosis when compared to a baseline classifier in which no uncertainty-aware strategy was included. In both applications, as well as reducing the ECE there was a slight increase in accuracy from 69% to 70% and 70% to 72% for CRT response prediction and CAD diagnosis respectively. However, our analysis showed a lack of consistency in terms of optimal models when using different calibration measures. This indicates the need for careful consideration of performance metrics when training and selecting models for complex high risk applications in healthcare.",10.1016/j.media.2023.102861
Revealing Unforeseen Diagnostic Image Features With Deep Learning by Detecting Cardiovascular Diseases From Apical 4-Chamber Ultrasounds.,Journal of the American Heart Association,2022,"Background With the increase of highly portable, wireless, and low-cost ultrasound devices and automatic ultrasound acquisition techniques, an automated interpretation method requiring only a limited set of views as input could make preliminary cardiovascular disease diagnoses more accessible. In this study, we developed a deep learning method for automated detection of impaired left ventricular (LV) function and aortic valve (AV) regurgitation from apical 4-chamber ultrasound cineloops and investigated which anatomical structures or temporal frames provided the most relevant information for the deep learning model to enable disease classification. Methods and Results Apical 4-chamber ultrasounds were extracted from 3554 echocardiograms of patients with impaired LV function (n=928), AV regurgitation (n=738), or no significant abnormalities (n=1888). Two convolutional neural networks were trained separately to classify the respective disease cases against normal cases. The overall classification accuracy of the impaired LV function detection model was 86%, and that of the AV regurgitation detection model was 83%. Feature importance analyses demonstrated that the LV myocardium and mitral valve were important for detecting impaired LV function, whereas the tip of the mitral valve anterior leaflet, during opening, was considered important for detecting AV regurgitation. Conclusions The proposed method demonstrated the feasibility of a 3-dimensional convolutional neural network approach in detection of impaired LV function and AV regurgitation using apical 4-chamber ultrasound cineloops. The current study shows that deep learning methods can exploit large training data to detect diseases in a different way than conventionally agreed on methods, and potentially reveal unforeseen diagnostic image features.",10.1161/JAHA.121.024168
Super-Resolution of Cardiac MR Cine Imaging using Conditional GANs and Unsupervised Transfer Learning.,Medical image analysis,2021,"High-resolution (HR), isotropic cardiac Magnetic Resonance (MR) cine imaging is challenging since it requires long acquisition and patient breath-hold times. Instead, 2D balanced steady-state free precession (SSFP) sequence is widely used in clinical routine. However, it produces highly-anisotropic image stacks, with large through-plane spacing that can hinder subsequent image analysis. To resolve this, we propose a novel, robust adversarial learning super-resolution (SR) algorithm based on conditional generative adversarial nets (GANs), that incorporates a state-of-the-art optical flow component to generate an auxiliary image to guide image synthesis. The approach is designed for real-world clinical scenarios and requires neither multiple low-resolution (LR) scans with multiple views, nor the corresponding HR scans, and is trained in an end-to-end unsupervised transfer learning fashion. The designed framework effectively incorporates visual properties and relevant structures of input images and can synthesise 3D isotropic, anatomically plausible cardiac MR images, consistent with the acquired slices. Experimental results show that the proposed SR method outperforms several state-of-the-art methods both qualitatively and quantitatively. We show that subsequent image analyses including ventricle segmentation, cardiac quantification, and non-rigid registration can benefit from the super-resolved, isotropic cardiac MR images, to produce more accurate quantitative results, without increasing the acquisition time. The average Dice similarity coefficient (DSC) for the left ventricular (LV) cavity and myocardium are 0.95 and 0.81, respectively, between real and synthesised slice segmentation. For non-rigid registration and motion tracking through the cardiac cycle, the proposed method improves the average DSC from 0.75 to 0.86, compared to the original resolution images.",10.1016/j.media.2021.102037
Deep learning methods for automatic evaluation of delayed enhancement-MRI. The results of the EMIDEC challenge.,Medical image analysis,2022,"A key factor for assessing the state of the heart after myocardial infarction (MI) is to measure whether the myocardium segment is viable after reperfusion or revascularization therapy. Delayed enhancement-MRI or DE-MRI, which is performed 10 min after injection of the contrast agent, provides high contrast between viable and nonviable myocardium and is therefore a method of choice to evaluate the extent of MI. To automatically assess myocardial status, the results of the EMIDEC challenge that focused on this task are presented in this paper. The challenge's main objectives were twofold. First, to evaluate if deep learning methods can distinguish between non-infarct and pathological exams, i.e. exams with or without hyperenhanced area. Second, to automatically calculate the extent of myocardial infarction. The publicly available database consists of 150 exams divided into 50 cases without any hyperenhanced area after injection of a contrast agent and 100 cases with myocardial infarction (and then with a hyperenhanced area on DE-MRI), whatever their inclusion in the cardiac emergency department. Along with MRI, clinical characteristics are also provided. The obtained results issued from several works show that the automatic classification of an exam is a reachable task (the best method providing an accuracy of 0.92), and the automatic segmentation of the myocardium is possible. However, the segmentation of the diseased area needs to be improved, mainly due to the small size of these areas and the lack of contrast with the surrounding structures.",10.1016/j.media.2022.102428
Learning-Based Regularization for Cardiac Strain Analysis via Domain Adaptation.,IEEE transactions on medical imaging,2021,"Reliable motion estimation and strain analysis using 3D+ time echocardiography (4DE) for localization and characterization of myocardial injury is valuable for early detection and targeted interventions. However, motion estimation is difficult due to the low-SNR that stems from the inherent image properties of 4DE, and intelligent regularization is critical for producing reliable motion estimates. In this work, we incorporated the notion of domain adaptation into a supervised neural network regularization framework. We first propose a semi-supervised Multi-Layered Perceptron (MLP) network with biomechanical constraints for learning a latent representation that is shown to have more physiologically plausible displacements. We extended this framework to include a supervised loss term on synthetic data and showed the effects of biomechanical constraints on the network's ability for domain adaptation. We validated the semi-supervised regularization method on in vivo data with implanted sonomicrometers. Finally, we showed the ability of our semi-supervised learning regularization approach to identify infarct regions using estimated regional strain maps with good agreement to manually traced infarct regions from postmortem excised hearts.",10.1109/TMI.2021.3074033
Few-Shot Learning by a Cascaded Framework With Shape-Constrained Pseudo Label Assessment for Whole Heart Segmentation.,IEEE transactions on medical imaging,2021,"Automatic and accurate 3D cardiac image segmentation plays a crucial role in cardiac disease diagnosis and treatment. Even though CNN based techniques have achieved great success in medical image segmentation, the expensive annotation, large memory consumption, and insufficient generalization ability still pose challenges to their application in clinical practice, especially in the case of 3D segmentation from high-resolution and large-dimension volumetric imaging. In this paper, we propose a few-shot learning framework by combining ideas of semi-supervised learning and self-training for whole heart segmentation and achieve promising accuracy with a Dice score of 0.890 and a Hausdorff distance of 18.539 mm with only four labeled data for training. When more labeled data provided, the model can generalize better across institutions. The key to success lies in the selection and evolution of high-quality pseudo labels in cascaded learning. A shape-constrained network is built to assess the quality of pseudo labels, and the self-training stages with alternative global-local perspectives are employed to improve the pseudo labels. We evaluate our method on the CTA dataset of the MM-WHS 2017 Challenge and a larger multi-center dataset. In the experiments, our method outperforms the state-of-the-art methods significantly and has great generalization ability on the unseen data. We also demonstrate, by a study of two 4D (3D+T) CTA data, the potential of our method to be applied in clinical practice.",10.1109/TMI.2021.3053008
Patient-Specific Heart Geometry Modeling for Solid Biomechanics Using Deep Learning.,IEEE transactions on medical imaging,2024,"Automated volumetric meshing of patient-specific heart geometry can help expedite various biomechanics studies, such as post-intervention stress estimation. Prior meshing techniques often neglect important modeling characteristics for successful downstream analyses, especially for thin structures like the valve leaflets. In this work, we present DeepCarve (Deep Cardiac Volumetric Mesh): a novel deformation-based deep learning method that automatically generates patient-specific volumetric meshes with high spatial accuracy and element quality. The main novelty in our method is the use of minimally sufficient surface mesh labels for precise spatial accuracy and the simultaneous optimization of isotropic and anisotropic deformation energies for volumetric mesh quality. Mesh generation takes only 0.13 seconds/scan during inference, and each mesh can be directly used for finite element analyses without any manual post-processing. Calcification meshes can also be subsequently incorporated for increased simulation accuracy. Numerous stent deployment simulations validate the viability of our approach for large-batch analyses. Our code is available at https://github.com/danpak94/Deep-Cardiac-Volumetric-Mesh.",10.1109/TMI.2023.3294128
On the usability of synthetic data for improving the robustness of deep learning-based segmentation of cardiac magnetic resonance images.,Medical image analysis,2023,"Deep learning-based segmentation methods provide an effective and automated way for assessing the structure and function of the heart in cardiac magnetic resonance (CMR) images. However, despite their state-of-the-art performance on images acquired from the same source (same scanner or scanner vendor) as images used during training, their performance degrades significantly on images coming from different domains. A straightforward approach to tackle this issue consists of acquiring large quantities of multi-site and multi-vendor data, which is practically infeasible. Generative adversarial networks (GANs) for image synthesis present a promising solution for tackling data limitations in medical imaging and addressing the generalization capability of segmentation models. In this work, we explore the usability of synthesized short-axis CMR images generated using a segmentation-informed conditional GAN, to improve the robustness of heart cavity segmentation models in a variety of different settings. The GAN is trained on paired real images and corresponding segmentation maps belonging to both the heart and the surrounding tissue, reinforcing the synthesis of semantically-consistent and realistic images. First, we evaluate the segmentation performance of a model trained solely with synthetic data and show that it only slightly underperforms compared to the baseline trained with real data. By further combining real with synthetic data during training, we observe a substantial improvement in segmentation performance (up to 4% and 40% in terms of Dice score and Hausdorff distance) across multiple data-sets collected from various sites and scanner. This is additionally demonstrated across state-of-the-art 2D and 3D segmentation networks, whereby the obtained results demonstrate the potential of the proposed method in tackling the presence of the domain shift in medical data. Finally, we thoroughly analyze the quality of synthetic data and its ability to replace real MR images during training, as well as provide an insight into important aspects of utilizing synthetic images for segmentation.",10.1016/j.media.2022.102688
Electromechanical Wave Imaging With Machine Learning for Automated Isochrone Generation.,IEEE transactions on medical imaging,2021,"Standard Electromechanical Wave Imaging isochrone generation relies on manual selection of zero-crossing (ZC) locations on incremental strain curves for a number of pixels in the segmented myocardium for each echocardiographic view and patient. When considering large populations, this becomes a time-consuming process, that can be limited by inter-observer variability and operator bias. In this study, we developed and optimized an automated ZC selection algorithm, towards a faster more robust isochrone generation approach. The algorithm either relies on heuristic-based baselines or machine learning classifiers. Manually generated isochrones, previously validated against 3D intracardiac mapping, were considered as ground truth during training and performance evaluation steps. The machine learning models applied herein for the first time were: i) logistic regression; ii) support vector machine (SVM); and iii) Random Forest. The SVM and Random Forest classifiers successfully identified accessory pathways in Wolff-Parkinson-White patients, characterized sinus rhythm in humans, and localized the pacing electrode location in left ventricular paced canines on the resulting isochrones. Nevertheless, the best performing classifier was proven to be Random Forest with a precision rising from 89.5% to 97%, obtained with the voting approach that sets a probability threshold upon ZC candidate selection. Furthermore, the predictivity was not dependent on the type of testing dataset it was applied to, contrary to SVM that exhibited a 5% drop in precision on the canine testing dataset. Finally, these findings indicate that a machine learning approach can reduce user variability and considerably decrease the durations required for isochrone generation, while preserving accurate activation patterns.",10.1109/TMI.2021.3074808
Adaptive Hierarchical Dual Consistency for Semi-Supervised Left Atrium Segmentation on Cross-Domain Data.,IEEE transactions on medical imaging,2022,"Semi-supervised learning provides great significance in left atrium (LA) segmentation model learning with insufficient labelled data. Generalising semi-supervised learning to cross-domain data is of high importance to further improve model robustness. However, the widely existing distribution difference and sample mismatch between different data domains hinder the generalisation of semi-supervised learning. In this study, we alleviate these problems by proposing an Adaptive Hierarchical Dual Consistency (AHDC) for the semi-supervised LA segmentation on cross-domain data. The AHDC mainly consists of a Bidirectional Adversarial Inference module (BAI) and a Hierarchical Dual Consistency learning module (HDC). The BAI overcomes the difference of distributions and the sample mismatch between two different domains. It mainly learns two mapping networks adversarially to obtain two matched domains through mutual adaptation. The HDC investigates a hierarchical dual learning paradigm for cross-domain semi-supervised segmentation based on the obtained matched domains. It mainly builds two dual-modelling networks for mining the complementary information in both intra-domain and inter-domain. For the intra-domain learning, a consistency constraint is applied to the dual-modelling targets to exploit the complementary modelling information. For the inter-domain learning, a consistency constraint is applied to the LAs modelled by two dual-modelling networks to exploit the complementary knowledge among different data domains. We demonstrated the performance of our proposed AHDC on four 3D late gadolinium enhancement cardiac MR (LGE-CMR) datasets from different centres and a 3D CT dataset. Compared to other state-of-the-art methods, our proposed AHDC achieved higher segmentation accuracy, which indicated its capability in the cross-domain semi-supervised LA segmentation.",10.1109/TMI.2021.3113678
Learned iterative segmentation of highly variable anatomy from limited data: Applications to whole heart segmentation for congenital heart disease.,Medical image analysis,2022,"Training deep learning models that segment an image in one step typically requires a large collection of manually annotated images that captures the anatomical variability in a cohort. This poses challenges when anatomical variability is extreme but training data is limited, as when segmenting cardiac structures in patients with congenital heart disease (CHD). In this paper, we propose an iterative segmentation model and show that it can be accurately learned from a small dataset. Implemented as a recurrent neural network, the model evolves a segmentation over multiple steps, from a single user click until reaching an automatically determined stopping point. We develop a novel loss function that evaluates the entire sequence of output segmentations, and use it to learn model parameters. Segmentations evolve predictably according to growth dynamics encapsulated by training data, which consists of images, partially completed segmentations, and the recommended next step. The user can easily refine the final segmentation by examining those that are earlier or later in the output sequence. Using a dataset of 3D cardiac MR scans from patients with a wide range of CHD types, we show that our iterative model offers better generalization to patients with the most severe heart malformations.",10.1016/j.media.2022.102469
SequenceMorph: A Unified Unsupervised Learning Framework for Motion Tracking on Cardiac Image Sequences.,IEEE transactions on pattern analysis and machine intelligence,2023,"Modern medical imaging techniques, such as ultrasound (US) and cardiac magnetic resonance (MR) imaging, have enabled the evaluation of myocardial deformation directly from an image sequence. While many traditional cardiac motion tracking methods have been developed for the automated estimation of the myocardial wall deformation, they are not widely used in clinical diagnosis, due to their lack of accuracy and efficiency. In this paper, we propose a novel deep learning-based fully unsupervised method, SequenceMorph, for in vivo motion tracking in cardiac image sequences. In our method, we introduce the concept of motion decomposition and recomposition. We first estimate the inter-frame (INF) motion field between any two consecutive frames, by a bi-directional generative diffeomorphic registration neural network. Using this result, we then estimate the Lagrangian motion field between the reference frame and any other frame, through a differentiable composition layer. Our framework can be extended to incorporate another registration network, to further reduce the accumulated errors introduced in the INF motion tracking step, and to refine the Lagrangian motion estimation. By utilizing temporal information to perform reasonable estimations of spatio-temporal motion fields, this novel method provides a useful solution for image sequence motion tracking. Our method has been applied to US (echocardiographic) and cardiac MR (untagged and tagged cine) image sequences; the results show that SequenceMorph is significantly superior to conventional motion tracking methods, in terms of the cardiac motion tracking accuracy and inference efficiency.",10.1109/TPAMI.2023.3243040
Utility of a Deep-Learning Algorithm to Guide Novices to Acquire Echocardiograms for Limited Diagnostic Use.,JAMA cardiology,2021,"Artificial intelligence (AI) has been applied to analysis of medical imaging in recent years, but AI to guide the acquisition of ultrasonography images is a novel area of investigation. A novel deep-learning (DL) algorithm, trained on more than 5 million examples of the outcome of ultrasonographic probe movement on image quality, can provide real-time prescriptive guidance for novice operators to obtain limited diagnostic transthoracic echocardiographic images.",10.1001/jamacardio.2021.0185
Contrastive Semi-Supervised Learning for Domain Adaptive Segmentation Across Similar Anatomical Structures.,IEEE transactions on medical imaging,2023,"Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance for medical image segmentation, yet need plenty of manual annotations for training. Semi-Supervised Learning (SSL) methods are promising to reduce the requirement of annotations, but their performance is still limited when the dataset size and the number of annotated images are small. Leveraging existing annotated datasets with similar anatomical structures to assist training has a potential for improving the model's performance. However, it is further challenged by the cross-anatomy domain shift due to the image modalities and even different organs in the target domain. To solve this problem, we propose Contrastive Semi-supervised learning for Cross Anatomy Domain Adaptation (CS-CADA) that adapts a model to segment similar structures in a target domain, which requires only limited annotations in the target domain by leveraging a set of existing annotated images of similar structures in a source domain. We use Domain-Specific Batch Normalization (DSBN) to individually normalize feature maps for the two anatomical domains, and propose a cross-domain contrastive learning strategy to encourage extracting domain invariant features. They are integrated into a Self-Ensembling Mean-Teacher (SE-MT) framework to exploit unlabeled target domain images with a prediction consistency constraint. Extensive experiments show that our CS-CADA is able to solve the challenging cross-anatomy domain shift problem, achieving accurate segmentation of coronary arteries in X-ray images with the help of retinal vessel images and cardiac MR images with the help of fundus images, respectively, given only a small number of annotations in the target domain. Our code is available at https://github.com/HiLab-git/DAG4MIA.",10.1109/TMI.2022.3209798
Deep Learning for Automatic Calcium Scoring in Population-Based Cardiovascular Screening.,JACC. Cardiovascular imaging,2022,,10.1016/j.jcmg.2021.07.012
Local contrastive loss with pseudo-label based self-training for semi-supervised medical image segmentation.,Medical image analysis,2023,"Supervised deep learning-based methods yield accurate results for medical image segmentation. However, they require large labeled datasets for this, and obtaining them is a laborious task that requires clinical expertise. Semi/self-supervised learning-based approaches address this limitation by exploiting unlabeled data along with limited annotated data. Recent self-supervised learning methods use contrastive loss to learn good global level representations from unlabeled images and achieve high performance in classification tasks on popular natural image datasets like ImageNet. In pixel-level prediction tasks such as segmentation, it is crucial to also learn good local level representations along with global representations to achieve better accuracy. However, the impact of the existing local contrastive loss-based methods remains limited for learning good local representations because similar and dissimilar local regions are defined based on random augmentations and spatial proximity; not based on the semantic label of local regions due to lack of large-scale expert annotations in the semi/self-supervised setting. In this paper, we propose a local contrastive loss to learn good pixel level features useful for segmentation by exploiting semantic label information obtained from pseudo-labels of unlabeled images alongside limited annotated images with ground truth (GT) labels. In particular, we define the proposed contrastive loss to encourage similar representations for the pixels that have the same pseudo-label/GT label while being dissimilar to the representation of pixels with different pseudo-label/GT label in the dataset. We perform pseudo-label based self-training and train the network by jointly optimizing the proposed contrastive loss on both labeled and unlabeled sets and segmentation loss on only the limited labeled set. We evaluated the proposed approach on three public medical datasets of cardiac and prostate anatomies, and obtain high segmentation performance with a limited labeled set of one or two 3D volumes. Extensive comparisons with the state-of-the-art semi-supervised and data augmentation methods and concurrent contrastive learning methods demonstrate the substantial improvement achieved by the proposed method. The code is made publicly available at https://github.com/krishnabits001/pseudo_label_contrastive_training.",10.1016/j.media.2023.102792
AI Based CMR Assessment of Biventricular Function: Clinical Significance of Intervendor Variability and Measurement Errors.,JACC. Cardiovascular imaging,2022,The aim of this study was to determine whether left ventricular ejection fraction (LVEF) and right ventricular ejection fraction (RVEF) and left ventricular mass (LVM) measurements made using 3 fully automated deep learning (DL) algorithms are accurate and interchangeable and can be used to classify ventricular function and risk-stratify patients as accurately as an expert.,10.1016/j.jcmg.2021.08.011
An Anatomy- and Topology-Preserving Framework for Coronary Artery Segmentation.,IEEE transactions on medical imaging,2024,"Coronary artery segmentation is critical for coronary artery disease diagnosis but challenging due to its tortuous course with numerous small branches and inter-subject variations. Most existing studies ignore important anatomical information and vascular topologies, leading to less desirable segmentation performance that usually cannot satisfy clinical demands. To deal with these challenges, in this paper we propose an anatomy- and topology-preserving two-stage framework for coronary artery segmentation. The proposed framework consists of an anatomical dependency encoding (ADE) module and a hierarchical topology learning (HTL) module for coarse-to-fine segmentation, respectively. Specifically, the ADE module segments four heart chambers and aorta, and thus five distance field maps are obtained to encode distance between chamber surfaces and coarsely segmented coronary artery. Meanwhile, ADE also performs coronary artery detection to crop region-of-interest and eliminate foreground-background imbalance. The follow-up HTL module performs fine segmentation by exploiting three hierarchical vascular topologies, i.e., key points, centerlines, and neighbor connectivity using a multi-task learning scheme. In addition, we adopt a bottom-up attention interaction (BAI) module to integrate the feature representations extracted across hierarchical topologies. Extensive experiments on public and in-house datasets show that the proposed framework achieves state-of-the-art performance for coronary artery segmentation.",10.1109/TMI.2023.3319720
Self-supervised learning for medical image data with anatomy-oriented imaging planes.,Medical image analysis,2024,"Self-supervised learning has emerged as a powerful tool for pretraining deep networks on unlabeled data, prior to transfer learning of target tasks with limited annotation. The relevance between the pretraining pretext and target tasks is crucial to the success of transfer learning. Various pretext tasks have been proposed to utilize properties of medical image data (e.g., three dimensionality), which are more relevant to medical image analysis than generic ones for natural images. However, previous work rarely paid attention to data with anatomy-oriented imaging planes, e.g., standard cardiac magnetic resonance imaging views. As these imaging planes are defined according to the anatomy of the imaged organ, pretext tasks effectively exploiting this information can pretrain the networks to gain knowledge on the organ of interest. In this work, we propose two complementary pretext tasks for this group of medical image data based on the spatial relationship of the imaging planes. The first is to learn the relative orientation between the imaging planes and implemented as regressing their intersecting lines. The second exploits parallel imaging planes to regress their relative slice locations within a stack. Both pretext tasks are conceptually straightforward and easy to implement, and can be combined in multitask learning for better representation learning. Thorough experiments on two anatomical structures (heart and knee) and representative target tasks (semantic segmentation and classification) demonstrate that the proposed pretext tasks are effective in pretraining deep networks for remarkably boosted performance on the target tasks, and superior to other recent approaches.",10.1016/j.media.2024.103151
A Deep Learning Pipeline for Assessing Ventricular Volumes from a Cardiac MRI Registry of Patients with Single Ventricle Physiology.,Radiology. Artificial intelligence,2024,"Purpose To develop an end-to-end deep learning (DL) pipeline for automated ventricular segmentation of cardiac MRI data from a multicenter registry of patients with Fontan circulation (Fontan Outcomes Registry Using CMR Examinations [FORCE]). Materials and Methods This retrospective study used 250 cardiac MRI examinations (November 2007-December 2022) from 13 institutions for training, validation, and testing. The pipeline contained three DL models: a classifier to identify short-axis cine stacks and two U-Net 3+ models for image cropping and segmentation. The automated segmentations were evaluated on the test set (<i>n</i> = 50) by using the Dice score. Volumetric and functional metrics derived from DL and ground truth manual segmentations were compared using Bland-Altman and intraclass correlation analysis. The pipeline was further qualitatively evaluated on 475 unseen examinations. Results There were acceptable limits of agreement (LOA) and minimal biases between the ground truth and DL end-diastolic volume (EDV) (bias: -0.6 mL/m<sup>2</sup>, LOA: -20.6 to 19.5 mL/m<sup>2</sup>) and end-systolic volume (ESV) (bias: -1.1 mL/m<sup>2</sup>, LOA: -18.1 to 15.9 mL/m<sup>2</sup>), with high intraclass correlation coefficients (ICCs > 0.97) and Dice scores (EDV, 0.91 and ESV, 0.86). There was moderate agreement for ventricular mass (bias: -1.9 g/m<sup>2</sup>, LOA: -17.3 to 13.5 g/m<sup>2</sup>) and an ICC of 0.94. There was also acceptable agreement for stroke volume (bias: 0.6 mL/m<sup>2</sup>, LOA: -17.2 to 18.3 mL/m<sup>2</sup>) and ejection fraction (bias: 0.6%, LOA: -12.2% to 13.4%), with high ICCs (>0.81). The pipeline achieved satisfactory segmentation in 68% of the 475 unseen examinations, while 26% needed minor adjustments, 5% needed major adjustments, and in 0.4%, the cropping model failed. Conclusion The DL pipeline can provide fast standardized segmentation for patients with single ventricle physiology across multiple centers. This pipeline can be applied to all cardiac MRI examinations in the FORCE registry. <b>Keywords:</b> Cardiac, Adults and Pediatrics, MR Imaging, Congenital, Volume Analysis, Segmentation, Quantification <i>Supplemental material is available for this article.</i> © RSNA, 2023.",10.1148/ryai.230132
A Deep Learning Method for Motion Artifact Correction in Intravascular Photoacoustic Image Sequence.,IEEE transactions on medical imaging,2023,"In vivo application of intravascular photoacoustic (IVPA) imaging for coronary arteries is hampered by motion artifacts associated with the cardiac cycle. Gating is a common strategy to mitigate motion artifacts. However, a large amount of diagnostically valuable information might be lost due to one frame per cycle. In this work, we present a deep learning-based method for directly correcting motion artifacts in non-gated IVPA pullback sequences. The raw signal frames are classified into dynamic and static frames by clustering. Then, a neural network named Motion Artifact Correction (MAC)-Net is designed to correct motion in dynamic frames. Given the lack of the ground truth information on the underlying dynamics of coronary arteries, we trained and tested the network using a computer-generated dataset. Based on the results, it has been observed that the trained network can directly correct motion in successive frames while preserving the original structures without discarding any frames. The improvement in the visual effect of the longitudinal view has been demonstrated based on quantitative evaluation of the inter-frame dissimilarity. The comparison results validated the motion-suppression ability of our method comparable to gating and image registration-based non-learning methods, while maintaining the integrity of the pullbacks without image preprocessing. Experimental results from in vivo intravascular ultrasound and optical coherence tomography pullbacks validated the feasibility of our method in the in vivo intracoronary imaging scenario.",10.1109/TMI.2022.3202910
Labelling with dynamics: A data-efficient learning paradigm for medical image segmentation.,Medical image analysis,2024,"The success of deep learning on image classification and recognition tasks has led to new applications in diverse contexts, including the field of medical imaging. However, two properties of deep neural networks (DNNs) may limit their future use in medical applications. The first is that DNNs require a large amount of labeled training data, and the second is that the deep learning-based models lack interpretability. In this paper, we propose and investigate a data-efficient framework for the task of general medical image segmentation. We address the two aforementioned challenges by introducing domain knowledge in the form of a strong prior into a deep learning framework. This prior is expressed by a customized dynamical system. We performed experiments on two different datasets, namely JSRT and ISIC2016 (heart and lungs segmentation on chest X-ray images and skin lesion segmentation on dermoscopy images). We have achieved competitive results using the same amount of training data compared to the state-of-the-art methods. More importantly, we demonstrate that our framework is extremely data-efficient, and it can achieve reliable results using extremely limited training data. Furthermore, the proposed method is rotationally invariant and insensitive to initialization.",10.1016/j.media.2024.103196
Domain Adaptation Meets Zero-Shot Learning: An Annotation-Efficient Approach to Multi-Modality Medical Image Segmentation.,IEEE transactions on medical imaging,2022,"Due to the lack of properly annotated medical data, exploring the generalization capability of the deep model is becoming a public concern. Zero-shot learning (ZSL) has emerged in recent years to equip the deep model with the ability to recognize unseen classes. However, existing studies mainly focus on natural images, which utilize linguistic models to extract auxiliary information for ZSL. It is impractical to apply the natural image ZSL solutions directly to medical images, since the medical terminology is very domain-specific, and it is not easy to acquire linguistic models for the medical terminology. In this work, we propose a new paradigm of ZSL specifically for medical images utilizing cross-modality information. We make three main contributions with the proposed paradigm. First, we extract the prior knowledge about the segmentation targets, called relation prototypes, from the prior model and then propose a cross-modality adaptation module to inherit the prototypes to the zero-shot model. Second, we propose a relation prototype awareness module to make the zero-shot model aware of information contained in the prototypes. Last but not least, we develop an inheritance attention module to recalibrate the relation prototypes to enhance the inheritance process. The proposed framework is evaluated on two public cross-modality datasets including a cardiac dataset and an abdominal dataset. Extensive experiments show that the proposed framework significantly outperforms the state of the arts.",10.1109/TMI.2021.3131245
Breaking Neural Reasoning Architectures With Metamorphic Relation-Based Adversarial Examples.,IEEE transactions on neural networks and learning systems,2022,"The ability to read, reason, and infer lies at the heart of neural reasoning architectures. After all, the ability to perform logical reasoning over language remains a coveted goal of Artificial Intelligence. To this end, models such as the Turing-complete differentiable neural computer (DNC) boast of real logical reasoning capabilities, along with the ability to reason beyond simple surface-level matching. In this brief, we propose the first probe into DNC's logical reasoning capabilities with a focus on text-based question answering (QA). More concretely, we propose a conceptually simple but effective adversarial attack based on metamorphic relations. Our proposed adversarial attack reduces DNCs' state-of-the-art accuracy from 100% to 1.5% in the worst case, exposing weaknesses and susceptibilities in modern neural reasoning architectures. We further empirically explore possibilities to defend against such attacks and demonstrate the utility of our adversarial framework as a simple scalable method to improve model adversarial robustness.",10.1109/TNNLS.2021.3072166
Mutual learning with reliable pseudo label for semi-supervised medical image segmentation.,Medical image analysis,2024,"Semi-supervised learning has garnered significant interest as a method to alleviate the burden of data annotation. Recently, semi-supervised medical image segmentation has garnered significant interest that can alleviate the burden of densely annotated data. Substantial advancements have been achieved by integrating consistency-regularization and pseudo-labeling techniques. The quality of the pseudo-labels is crucial in this regard. Unreliable pseudo-labeling can result in the introduction of noise, leading the model to converge to suboptimal solutions. To address this issue, we propose learning from reliable pseudo-labels. In this paper, we tackle two critical questions in learning from reliable pseudo-labels: which pseudo-labels are reliable and how reliable are they? Specifically, we conduct a comparative analysis of two subnetworks to address both challenges. Initially, we compare the prediction confidence of the two subnetworks. A higher confidence score indicates a more reliable pseudo-label. Subsequently, we utilize intra-class similarity to assess the reliability of the pseudo-labels to address the second challenge. The greater the intra-class similarity of the predicted classes, the more reliable the pseudo-label. The subnetwork selectively incorporates knowledge imparted by the other subnetwork model, contingent on the reliability of the pseudo labels. By reducing the introduction of noise from unreliable pseudo-labels, we are able to improve the performance of segmentation. To demonstrate the superiority of our approach, we conducted an extensive set of experiments on three datasets: Left Atrium, Pancreas-CT and Brats-2019. The experimental results demonstrate that our approach achieves state-of-the-art performance. Code is available at: https://github.com/Jiawei0o0/mutual-learning-with-reliable-pseudo-labels.",10.1016/j.media.2024.103111
A deep learning solution to detect left ventricular structural abnormalities with chest X-rays: towards trustworthy AI in cardiology.,European heart journal,2024,,10.1093/eurheartj/ehad775
Machine Learning Assessment of CAD: A Giant Leap or a Small Step for Coronary CTA?,JACC. Cardiovascular imaging,2023,,10.1016/j.jcmg.2022.12.021
Dual-Teacher++: Exploiting Intra-Domain and Inter-Domain Knowledge With Reliable Transfer for Cardiac Segmentation.,IEEE transactions on medical imaging,2021,"Annotation scarcity is a long-standing problem in medical image analysis area. To efficiently leverage limited annotations, abundant unlabeled data are additionally exploited in semi-supervised learning, while well-established cross-modality data are investigated in domain adaptation. In this paper, we aim to explore the feasibility of concurrently leveraging both unlabeled data and cross-modality data for annotation-efficient cardiac segmentation. To this end, we propose a cutting-edge semi-supervised domain adaptation framework, namely Dual-Teacher++. Besides directly learning from limited labeled target domain data (e.g., CT) via a student model adopted by previous literature, we design novel dual teacher models, including an inter-domain teacher model to explore cross-modality priors from source domain (e.g., MR) and an intra-domain teacher model to investigate the knowledge beneath unlabeled target domain. In this way, the dual teacher models would transfer acquired inter- and intra-domain knowledge to the student model for further integration and exploitation. Moreover, to encourag reliable dual-domain knowledge transfer, we enhance the inter-domain knowledge transfer on the samples with higher similarity to target domain after appearance alignment, and also strengthen intra-domain knowledge transfer of unlabeled target data with higher prediction confidence. In this way, the student model can obtain reliable dual-domain knowledge and yield improved performance on target domain data. We extensively evaluated the feasibility of our method on the MM-WHS 2017 challenge dataset. The experiments have demonstrated the superiority of our framework over other semi-supervised learning and domain adaptation methods. Moreover, our performance gains could be yielded in bidirections, i.e., adapting from MR to CT, and from CT to MR. Our code will be available at https://github.com/kli-lalala/Dual-Teacher-.",10.1109/TMI.2020.3038828
Modern Day Wearables to Evade the Widow-Ghost in Brugada Syndrome: From Mythology to Deep-Learning Methodology.,JACC. Clinical electrophysiology,2022,,10.1016/j.jacep.2022.06.017
Heart failure: from pathophysiology to deep learning-based outcome prediction.,European heart journal,2023,,10.1093/eurheartj/ehad065
Artificial Intelligence for Automatic Measurement of Left Ventricular Strain in Echocardiography.,JACC. Cardiovascular imaging,2021,This study sought to examine if fully automated measurements of global longitudinal strain (GLS) using a novel motion estimation technology based on deep learning and artificial intelligence (AI) are feasible and comparable with a conventional speckle-tracking application.,10.1016/j.jcmg.2021.04.018
Prediction of Coronary Stent Underexpansion by Pre-Procedural Intravascular Ultrasound-Based Deep Learning.,JACC. Cardiovascular interventions,2021,The aim of this study was to develop pre-procedural intravascular ultrasound (IVUS)-based models for predicting the occurrence of stent underexpansion.,10.1016/j.jcin.2021.01.033
Deep learning of early brain imaging to predict post-arrest electroencephalography.,Resuscitation,2022,Guidelines recommend use of computerized tomography (CT) and electroencephalography (EEG) in post-arrest prognostication. Strong associations between CT and EEG might obviate the need to acquire both modalities. We quantified these associations via deep learning.,10.1016/j.resuscitation.2022.01.004
Deep pyramid local attention neural network for cardiac structure segmentation in two-dimensional echocardiography.,Medical image analysis,2021,"Automatic semantic segmentation in 2D echocardiography is vital in clinical practice for assessing various cardiac functions and improving the diagnosis of cardiac diseases. However, two distinct problems have persisted in automatic segmentation in 2D echocardiography, namely the lack of an effective feature enhancement approach for contextual feature capture and lack of label coherence in category prediction for individual pixels. Therefore, in this study, we propose a deep learning model, called deep pyramid local attention neural network (PLANet), to improve the segmentation performance of automatic methods in 2D echocardiography. Specifically, we propose a pyramid local attention module to enhance features by capturing supporting information within compact and sparse neighboring contexts. We also propose a label coherence learning mechanism to promote prediction consistency for pixels and their neighbors by guiding the learning with explicit supervision signals. The proposed PLANet was extensively evaluated on the dataset of cardiac acquisitions for multi-structure ultrasound segmentation (CAMUS) and sub-EchoNet-Dynamic, which are two large-scale and public 2D echocardiography datasets. The experimental results show that PLANet performs better than traditional and deep learning-based segmentation methods on geometrical and clinical metrics. Moreover, PLANet can complete the segmentation of heart structures in 2D echocardiography in real time, indicating a potential to assist cardiologists accurately and efficiently.",10.1016/j.media.2020.101873
Toward Enabling Cardiac Digital Twins of Myocardial Infarction Using Deep Computational Models for Inverse Inference.,IEEE transactions on medical imaging,2024,"Cardiac digital twins (CDTs) have the potential to offer individualized evaluation of cardiac function in a non-invasive manner, making them a promising approach for personalized diagnosis and treatment planning of myocardial infarction (MI). The inference of accurate myocardial tissue properties is crucial in creating a reliable CDT of MI. In this work, we investigate the feasibility of inferring myocardial tissue properties from the electrocardiogram (ECG) within a CDT platform. The platform integrates multi-modal data, such as cardiac MRI and ECG, to enhance the accuracy and reliability of the inferred tissue properties. We perform a sensitivity analysis based on computer simulations, systematically exploring the effects of infarct location, size, degree of transmurality, and electrical activity alteration on the simulated QRS complex of ECG, to establish the limits of the approach. We subsequently present a novel deep computational model, comprising a dual-branch variational autoencoder and an inference model, to infer infarct location and distribution from the simulated QRS. The proposed model achieves mean Dice scores of 0.457 ±0.317 and 0.302 ±0.273 for the inference of left ventricle scars and border zone, respectively. The sensitivity analysis enhances our understanding of the complex relationship between infarct characteristics and electrophysiological features. The in silico experimental results show that the model can effectively capture the relationship for the inverse inference, with promising potential for clinical application in the future. The code is available at https://github.com/lileitech/MI_inverse_inference.",10.1109/TMI.2024.3367409
Deep Learning Algorithms to Detect Murmurs Associated With Structural Heart Disease.,Journal of the American Heart Association,2023,"Background The success of cardiac auscultation varies widely among medical professionals, which can lead to missed treatments for structural heart disease. Applying machine learning to cardiac auscultation could address this problem, but despite recent interest, few algorithms have been brought to clinical practice. We evaluated a novel suite of Food and Drug Administration-cleared algorithms trained via deep learning on >15 000 heart sound recordings. Methods and Results We validated the algorithms on a data set of 2375 recordings from 615 unique subjects. This data set was collected in real clinical environments using commercially available digital stethoscopes, annotated by board-certified cardiologists, and paired with echocardiograms as the gold standard. To model the algorithm in clinical practice, we compared its performance against 10 clinicians on a subset of the validation database. Our algorithm reliably detected structural murmurs with a sensitivity of 85.6% and specificity of 84.4%. When limiting the analysis to clearly audible murmurs in adults, performance improved to a sensitivity of 97.9% and specificity of 90.6%. The algorithm also reported timing within the cardiac cycle, differentiating between systolic and diastolic murmurs. Despite optimizing acoustics for the clinicians, the algorithm substantially outperformed the clinicians (average clinician accuracy, 77.9%; algorithm accuracy, 84.7%.) Conclusions The algorithms accurately identified murmurs associated with structural heart disease. Our results illustrate a marked contrast between the consistency of the algorithm and the substantial interobserver variability of clinicians. Our results suggest that adopting machine learning algorithms into clinical practice could improve the detection of structural heart disease to facilitate patient care.",10.1161/JAHA.123.030377
MisMatch: Calibrated Segmentation via Consistency on Differential Morphological Feature Perturbations With Limited Labels.,IEEE transactions on medical imaging,2023,"Semi-supervised learning (SSL) is a promising machine learning paradigm to address the ubiquitous issue of label scarcity in medical imaging. The state-of-the-art SSL methods in image classification utilise consistency regularisation to learn unlabelled predictions which are invariant to input level perturbations. However, image level perturbations violate the cluster assumption in the setting of segmentation. Moreover, existing image level perturbations are hand-crafted which could be sub-optimal. In this paper, we propose MisMatch, a semi-supervised segmentation framework based on the consistency between paired predictions which are derived from two differently learnt morphological feature perturbations. MisMatch consists of an encoder and two decoders. One decoder learns positive attention for foreground on unlabelled data thereby generating dilated features of foreground. The other decoder learns negative attention for foreground on the same unlabelled data thereby generating eroded features of foreground. We normalise the paired predictions of the decoders, along the batch dimension. A consistency regularisation is then applied between the normalised paired predictions of the decoders. We evaluate MisMatch on four different tasks. Firstly, we develop a 2D U-net based MisMatch framework and perform extensive cross-validation on a CT-based pulmonary vessel segmentation task and show that MisMatch statistically outperforms state-of-the-art semi-supervised methods. Secondly, we show that 2D MisMatch outperforms state-of-the-art methods on an MRI-based brain tumour segmentation task. We then further confirm that 3D V-net based MisMatch outperforms its 3D counterpart based on consistency regularisation with input level perturbations, on two different tasks including, left atrium segmentation from 3D CT images and whole brain tumour segmentation from 3D MRI images. Lastly, we find that the performance improvement of MisMatch over the baseline might originate from its better calibration. This also implies that our proposed AI system makes safer decisions than the previous methods.",10.1109/TMI.2023.3273158
A deep-learning approach for direct whole-heart mesh reconstruction.,Medical image analysis,2021,"Automated construction of surface geometries of cardiac structures from volumetric medical images is important for a number of clinical applications. While deep-learning-based approaches have demonstrated promising reconstruction precision, these approaches have mostly focused on voxel-wise segmentation followed by surface reconstruction and post-processing techniques. However, such approaches suffer from a number of limitations including disconnected regions or incorrect surface topology due to erroneous segmentation and stair-case artifacts due to limited segmentation resolution. We propose a novel deep-learning-based approach that directly predicts whole heart surface meshes from volumetric CT and MR image data. Our approach leverages a graph convolutional neural network to predict deformation on mesh vertices from a pre-defined mesh template to reconstruct multiple anatomical structures in a 3D image volume. Our method demonstrated promising performance of generating whole heart reconstructions with as good or better accuracy than prior deep-learning-based methods on both CT and MR data. Furthermore, by deforming a template mesh, our method can generate whole heart geometries with better anatomical consistency and produce high-resolution geometries from lower resolution input image data. Our method was also able to produce temporally-consistent surface mesh predictions for heart motion from CT or MR cine sequences, and therefore can potentially be applied for efficiently constructing 4D whole heart dynamics. Our code and pre-trained networks are available at https://github.com/fkong7/MeshDeformNet.",10.1016/j.media.2021.102222
Deep Learning to Estimate Biological Age From Chest Radiographs.,JACC. Cardiovascular imaging,2021,The goal of this study was to assess whether a deep learning estimate of age from a chest radiograph image (CXR-Age) can predict longevity beyond chronological age.,10.1016/j.jcmg.2021.01.008
Machine Learning Identifies Clinical Parameters to Predict Mortality in Patients Undergoing Transcatheter Mitral Valve Repair.,JACC. Cardiovascular interventions,2021,The aim of this study was to develop a machine learning (ML)-based risk stratification tool for 1-year mortality in transcatheter mitral valve repair (TMVR) patients incorporating metabolic and hemodynamic parameters.,10.1016/j.jcin.2021.06.039
Pushing the Limits of the ECG: Can We Assess Biventricular Function Without Imaging?,JACC. Cardiovascular imaging,2022,,10.1016/j.jcmg.2021.09.004
Functional Outcome Prediction in Acute Ischemic Stroke Using a Fused Imaging and Clinical Deep Learning Model.,Stroke,2023,"Predicting long-term clinical outcome based on the early acute ischemic stroke information is valuable for prognostication, resource management, clinical trials, and patient expectations. Current methods require subjective decisions about which imaging features to assess and may require time-consuming postprocessing. This study's goal was to predict ordinal 90-day modified Rankin Scale (mRS) score in acute ischemic stroke patients by fusing a Deep Learning model of diffusion-weighted imaging images and clinical information from the acute period.",10.1161/STROKEAHA.123.044072
Direct Risk Assessment From Myocardial Perfusion Imaging Using Explainable Deep Learning.,JACC. Cardiovascular imaging,2023,"Myocardial perfusion imaging (MPI) is frequently used to provide risk stratification, but methods to improve the accuracy of these predictions are needed.",10.1016/j.jcmg.2022.07.017
From Conventional Deep Learning to GPT: AI's Emergent Power for Cardiac Imaging.,JACC. Cardiovascular imaging,2023,,10.1016/j.jcmg.2023.07.001
Machine learning and the automated optimization of cardiac device parameters.,Heart rhythm,2023,,10.1016/j.hrthm.2023.06.008
"Deep Learning, Constrictive Pericarditis, and its Occasional Doppelganger: A Step Closer to Clinical Realization.",JACC. Cardiovascular imaging,2024,,10.1016/j.jcmg.2023.10.009
Supplementing Existing Societal Risk Models for Surgical Aortic Valve Replacement With Machine Learning for Improved Prediction.,Journal of the American Heart Association,2021,"Background This study evaluated the role of supplementing Society of Thoracic Surgeons (STS) risk models for surgical aortic valve replacement with machine learning (ML). Methods and Results Adults undergoing isolated surgical aortic valve replacement in the STS National Database between 2007 and 2017 were included. ML models for operative mortality and major morbidity were previously developed using extreme gradient boosting. Concordance and discordance in predicted risk between ML and STS models were defined using equal-size tertile-based thresholds of risk. Calibration metrics and discriminatory capability were compared between concordant and discordant patients. A total of 243 142 patients were included. Nearly all calibration metrics were improved in cases of concordance. Similarly, concordance indices improved substantially in cases of concordance for all models with the exception of deep sternal wound infection. The greatest improvements in concordant versus discordant cases were in renal failure: ML model (concordance index, 0.660 [95% CI, 0.632-0.687] discordant versus 0.808 [95% CI, 0.794-0.822] concordant) and STS model (concordance index, 0.573 [95% CI, 0.549-0.576] discordant versus 0.797 [95% CI, 0.782-0.811] concordant) (each <i>P</i><0.001). Excluding deep sternal wound infection, the concordance indices ranged from 0.549 to 0.660 for discordant cases and 0.674 to 0.808 for concordant cases. Conclusions Supplementing ML models with existing STS models for surgical aortic valve replacement may have an important role in risk prediction and should be explored further. In particular, for the roughly 25% to 50% of patients demonstrating discordance in estimated risk between ML and STS, there appears to be a substantial decline in predictive performance suggesting vulnerability of the existing models in these patient subsets.",10.1161/JAHA.120.019697
Deep learning approach to unmask hidden salt effects in the era of artificial intelligence.,European heart journal,2023,,10.1093/eurheartj/ehad673
A Machine-Learning Framework to Identify Distinct Phenotypes of Aortic Stenosis Severity.,JACC. Cardiovascular imaging,2021,The authors explored the development and validation of machine-learning models for augmenting the echocardiographic grading of aortic stenosis (AS) severity.,10.1016/j.jcmg.2021.03.020
"Race, Sex, and Age Disparities in the Performance of ECG Deep Learning Models Predicting Heart Failure.",Circulation. Heart failure,2024,"Deep learning models may combat widening racial disparities in heart failure outcomes through early identification of individuals at high risk. However, demographic biases in the performance of these models have not been well-studied.",10.1161/CIRCHEARTFAILURE.123.010879
Compete to Win: Enhancing Pseudo Labels for Barely-Supervised Medical Image Segmentation.,IEEE transactions on medical imaging,2023,"This study investigates barely-supervised medical image segmentation where only few labeled data, i.e., single-digit cases are available. We observe the key limitation of the existing state-of-the-art semi-supervised solution cross pseudo supervision is the unsatisfactory precision of foreground classes, leading to a degenerated result under barely-supervised learning. In this paper, we propose a novel Compete-to-Win method (ComWin) to enhance the pseudo label quality. In contrast to directly using one model's predictions as pseudo labels, our key idea is that high-quality pseudo labels should be generated by comparing multiple confidence maps produced by different networks to select the most confident one (a compete-to-win strategy). To further refine pseudo labels at near-boundary areas, an enhanced version of ComWin, namely, ComWin <sup>+</sup> , is proposed by integrating a boundary-aware enhancement module. Experiments show that our method can achieve the best performance on three public medical image datasets for cardiac structure segmentation, pancreas segmentation and colon tumor segmentation, respectively. The source code is now available at https://github.com/Huiimin5/comwin.",10.1109/TMI.2023.3279110
Echocardiography-Based Deep Learning Model to Differentiate Constrictive Pericarditis and Restrictive Cardiomyopathy.,JACC. Cardiovascular imaging,2024,"Constrictive pericarditis (CP) is an uncommon but reversible cause of diastolic heart failure if appropriately identified and treated. However, its diagnosis remains a challenge for clinicians. Artificial intelligence may enhance the identification of CP.",10.1016/j.jcmg.2023.09.011
Machine Learning-Enabled Multimodal Fusion of Intra-Atrial and Body Surface Signals in Prediction of Atrial Fibrillation Ablation Outcomes.,Circulation. Arrhythmia and electrophysiology,2022,"Machine learning is a promising approach to personalize atrial fibrillation management strategies for patients after catheter ablation. Prior atrial fibrillation ablation outcome prediction studies applied classical machine learning methods to hand-crafted clinical scores, and none have leveraged intracardiac electrograms or 12-lead surface electrocardiograms for outcome prediction. We hypothesized that (1) machine learning models trained on electrograms or electrocardiogram (ECG) signals can perform better at predicting patient outcomes after atrial fibrillation ablation than existing clinical scores and (2) multimodal fusion of electrogram, ECG, and clinical features can further improve the prediction of patient outcomes.",10.1161/CIRCEP.122.010850
Genetic Susceptibility to Atrial Fibrillation Identified via Deep Learning of 12-Lead Electrocardiograms.,Circulation. Genomic and precision medicine,2023,"Artificial intelligence (AI) models applied to 12-lead ECG waveforms can predict atrial fibrillation (AF), a heritable and morbid arrhythmia. However, the factors forming the basis of risk predictions from AI models are usually not well understood. We hypothesized that there might be a genetic basis for an AI algorithm for predicting the 5-year risk of new-onset AF using 12-lead ECGs (ECG-AI)-based risk estimates.",10.1161/CIRCGEN.122.003808
AV-casNet: Fully Automatic Arteriole-Venule Segmentation and Differentiation in OCT Angiography.,IEEE transactions on medical imaging,2023,"Automatic segmentation and differentiation of retinal arteriole and venule (AV), defined as small blood vessels directly before and after the capillary plexus, are of great importance for the diagnosis of various eye diseases and systemic diseases, such as diabetic retinopathy, hypertension, and cardiovascular diseases. Optical coherence tomography angiography (OCTA) is a recent imaging modality that provides capillary-level blood flow information. However, OCTA does not have the colorimetric and geometric differences between AV as the fundus photography does. Various methods have been proposed to differentiate AV in OCTA, which typically needs the guidance of other imaging modalities. In this study, we propose a cascaded neural network to automatically segment and differentiate AV solely based on OCTA. A convolutional neural network (CNN) module is first applied to generate an initial segmentation, followed by a graph neural network (GNN) to improve the connectivity of the initial segmentation. Various CNN and GNN architectures are employed and compared. The proposed method is evaluated on multi-center clinical datasets, including 3 ×3 mm2 and 6 ×6 mm2 OCTA. The proposed method holds the potential to enrich OCTA image information for the diagnosis of various diseases.",10.1109/TMI.2022.3214291
Automatic multi-view pose estimation in focused cardiac ultrasound.,Medical image analysis,2024,"Focused cardiac ultrasound (FoCUS) is a valuable point-of-care method for evaluating cardiovascular structures and function, but its scope is limited by equipment and operator's experience, resulting in primarily qualitative 2D exams. This study presents a novel framework to automatically estimate the 3D spatial relationship between standard FoCUS views. The proposed framework uses a multi-view U-Net-like fully convolutional neural network to regress line-based heatmaps representing the most likely areas of intersection between input images. The lines that best fit the regressed heatmaps are then extracted, and a system of nonlinear equations based on the intersection between view triplets is created and solved to determine the relative 3D pose between all input images. The feasibility and accuracy of the proposed pipeline were validated using a novel realistic in silico FoCUS dataset, demonstrating promising results. Interestingly, as shown in preliminary experiments, the estimation of the 2D images' relative poses enables the application of 3D image analysis methods and paves the way for 3D quantitative assessments in FoCUS examinations.",10.1016/j.media.2024.103146
Artificial Intelligence for Contrast-Free MRI: Scar Assessment in Myocardial Infarction Using Deep Learning-Based Virtual Native Enhancement.,Circulation,2022,"Myocardial scars are assessed noninvasively using cardiovascular magnetic resonance late gadolinium enhancement (LGE) as an imaging gold standard. A contrast-free approach would provide many advantages, including a faster and cheaper scan without contrast-associated problems.",10.1161/CIRCULATIONAHA.122.060137
Automated detection and segmentation of pulmonary embolisms on computed tomography pulmonary angiography (CTPA) using deep learning but without manual outlining.,Medical image analysis,2023,"We present a novel computer algorithm to automatically detect and segment pulmonary embolisms (PEs) on computed tomography pulmonary angiography (CTPA). This algorithm is based on deep learning but does not require manual outlines of the PE regions. Given a CTPA scan, both intra- and extra-pulmonary arteries were firstly segmented. The arteries were then partitioned into several parts based on size (radius). Adaptive thresholding and constrained morphological operations were used to identify suspicious PE regions within each part. The confidence of a suspicious region to be PE was scored based on its contrast in the arteries. This approach was applied to the publicly available RSNA Pulmonary Embolism CT Dataset (RSNA-PE) to identify three-dimensional (3-D) PE negative and positive image patches, which were used to train a 3-D Recurrent Residual U-Net (R2-Unet) to automatically segment PE. The feasibility of this computer algorithm was validated on an independent test set consisting of 91 CTPA scans acquired from a different medical institute, where the PE regions were manually located and outlined by a thoracic radiologist (>18 years' experience). An R2-Unet model was also trained and validated on the manual outlines using a 5-fold cross-validation method. The CNN model trained on the high-confident PE regions showed a Dice coefficient of 0.676±0.168 and a false positive rate of 1.86 per CT scan, while the CNN model trained on the manual outlines demonstrated a Dice coefficient of 0.647±0.192 and a false positive rate of 4.20 per CT scan. The former model performed significantly better than the latter model (p<0.01). The promising performance of the developed PE detection and segmentation algorithm suggests the feasibility of training a deep learning network without dedicating significant efforts to manual annotations of the PE regions on CTPA scans.",10.1016/j.media.2023.102882
Deep Learning-Based Prediction of Right Ventricular Ejection Fraction Using 2D Echocardiograms.,JACC. Cardiovascular imaging,2023,"Evidence has shown the independent prognostic value of right ventricular (RV) function, even in patients with left-sided heart disease. The most widely used imaging technique to measure RV function is echocardiography; however, conventional 2-dimensional (2D) echocardiographic assessment is unable to leverage the same clinical information that 3-dimensional (3D) echocardiography-derived right ventricular ejection fraction (RVEF) can provide.",10.1016/j.jcmg.2023.02.017
Microarchitectural Changes of Cardiovascular Calcification in Response to In Vivo Interventions Using Deep-Learning Segmentation and Computed Tomography Radiomics.,"Arteriosclerosis, thrombosis, and vascular biology",2022,"Coronary calcification associates closely with cardiovascular risk, but its progress is accelerated in response to some interventions widely used to reduce risk. This paradox suggests that qualitative, not just quantitative, changes in calcification may affect plaque stability. To determine if the microarchitecture of calcification varies with aging, Western diet, statin therapy, and high intensity, progressive exercise, we assessed changes in a priori selected computed tomography radiomic features (intensity, size, shape, and texture).",10.1161/ATVBAHA.122.317761
Electrocardiogram-based deep learning improves outcome prediction following cardiac resynchronization therapy.,European heart journal,2023,This study aims to identify and visualize electrocardiogram (ECG) features using an explainable deep learning-based algorithm to predict cardiac resynchronization therapy (CRT) outcome. Its performance is compared with current guideline ECG criteria and QRSAREA.,10.1093/eurheartj/ehac617
Topologic Data Analysis and Machine Learning: Defining the Aortic Valvular-Ventricular Disease Terrain.,JACC. Cardiovascular imaging,2021,,10.1016/j.jcmg.2021.04.005
Explainable Machine Learning to Predict Anchored Reentry Substrate Created by Persistent Atrial Fibrillation Ablation in Computational Models.,Journal of the American Heart Association,2023,"Background Postablation arrhythmia recurrence occurs in ~40% of patients with persistent atrial fibrillation. Fibrotic remodeling exacerbates arrhythmic activity in persistent atrial fibrillation and can play a key role in reentrant arrhythmia, but emergent interaction between nonconductive ablation-induced scar and native fibrosis (ie, residual fibrosis) is poorly understood. Methods and Results We conducted computational simulations in pre- and postablation left atrial models reconstructed from late gadolinium enhanced magnetic resonance imaging scans to test the hypothesis that ablation in patients with persistent atrial fibrillation creates new substrate conducive to recurrent arrhythmia mediated by anchored reentry. We trained a random forest machine learning classifier to accurately pinpoint specific nonconductive tissue regions (ie, areas of ablation-delivered scar or vein/valve boundaries) with the capacity to serve as substrate for anchored reentry-driven recurrent arrhythmia (area under the curve: 0.91±0.03). Our analysis suggests there is a distinctive nonconductive tissue pattern prone to serving as arrhythmogenic substrate in postablation models, defined by a specific size and proximity to residual fibrosis. Conclusions Overall, this suggests persistent atrial fibrillation ablation transforms substrate that favors functional reentry (ie, rotors meandering in excitable tissue) into an arrhythmogenic milieu more conducive to anchored reentry. Our work also indicates that explainable machine learning and computational simulations can be combined to effectively probe mechanisms of recurrent arrhythmia.",10.1161/JAHA.123.030500
Deep Learning-Enabled Assessment of Left Heart Structure and Function Predicts Cardiovascular Outcomes.,Journal of the American College of Cardiology,2023,Deep learning interpretation of echocardiographic images may facilitate automated assessment of cardiac structure and function.,10.1016/j.jacc.2023.09.800
Can Deep Learning Detect Incidental Abnormal Cardiac Uptake Related to Amyloidosis on Routine Bone Scintigraphy?,JACC. Cardiovascular imaging,2023,,10.1016/j.jcmg.2023.01.018
Shape constrained CNN for segmentation guided prediction of myocardial shape and pose parameters in cardiac MRI.,Medical image analysis,2022,"Semantic segmentation using convolutional neural networks (CNNs) is the state-of-the-art for many medical image segmentation tasks including myocardial segmentation in cardiac MR images. However, the predicted segmentation maps obtained from such standard CNN do not allow direct quantification of regional shape properties such as regional wall thickness. Furthermore, the CNNs lack explicit shape constraints, occasionally resulting in unrealistic segmentations. In this paper, we use a CNN to predict shape parameters of an underlying statistical shape model of the myocardium learned from a training set of images. Additionally, the cardiac pose is predicted, which allows to reconstruct the myocardial contours. The integrated shape model regularizes the predicted contours and guarantees realistic shapes. We enforce robustness of shape and pose prediction by simultaneously performing pixel-wise semantic segmentation during training and define two loss functions to impose consistency between the two predicted representations: one distance-based loss and one overlap-based loss. We evaluated the proposed method in a 5-fold cross validation on an in-house clinical dataset with 75 subjects and on the ACDC and LVQuan19 public datasets. We show that the two newly defined loss functions successfully increase the consistency between shape and pose parameters and semantic segmentation, which leads to a significant improvement of the reconstructed myocardial contours. Additionally, these loss functions drastically reduce the occurrence of unrealistic shapes in the semantic segmentation output.",10.1016/j.media.2022.102533
